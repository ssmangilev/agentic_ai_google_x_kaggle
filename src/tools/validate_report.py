from typing import Dict, List


def _check_hallucination_of_metric(draft_report: str, ground_truth_data: str, critiques: List[str]): # NOQA
    """
    Simulates checking if metrics or claims in the report
    are unsupported by the ground truth.

    A critical check for invented numbers or concepts.
    """
    # Abstract Check 1: Simulating an LLM identifying an unsupported concept.
    # Placeholder Logic: Checks if the report references
    # a hypothetical "foot traffic"
    # metric that is not present in the ground truth.
    if "foot traffic" in draft_report.lower() and "foot traffic" not in ground_truth_data.lower(): # NOQA
        critiques.append("Hallucination: The report introduces a metric ('foot traffic') unsupported by the Ground Truth data.") # NOQA


def _check_temporal_scope_mismatch(original_query: str, draft_report: str, critiques: List[str]): # NOQA
    """
    Simulates checking if the time scope
    analyzed matches the time scope requested.

    Ensures responsiveness to temporal parameters (e.g., Q3 vs Q4).
    """
    # Abstract Check 2: Simulating an LLM verifying temporal context.
    # Placeholder Logic: Checks if the query mentions
    # Q3 but the report shifts focus to Q4.
    if "Q3" in original_query and "Q4" in draft_report and "Q3" not in draft_report: # NOQA
        critiques.append("Responsiveness: Temporal Mismatch: User asked for Q3 analysis, but the report focuses on Q4.") # NOQA


def _check_core_query_addressal(original_query: str, draft_report: str, critiques: List[str]): # NOQA
    """
    Simulates checking if the report addresses
    the primary subject of the user's query.

    Ensures responsiveness to the topic (e.g., Campaign, Region, Product).
    """
    # Abstract Check 3: Simulating an LLM verifying the main topic is covered.
    # Placeholder Logic: Uses the first word of the query
    # (e.g., "How" or "Campaign") as the core subject.
    core_topic = original_query.split()[0].lower().replace("how", "").strip()
    if core_topic and core_topic not in draft_report.lower():
        critiques.append(f"Responsiveness: The report fails to directly address the core topic derived from the query: '{core_topic}'.") # NOQA


def _check_logical_contradiction(draft_report: str, ground_truth_data: str, critiques: List[str]): # NOQA
    """
    Simulates checking for internal logical
    errors between the data and the report's claims.

    Ensures consistency (e.g., claim of growth when data shows decline).
    """
    # Abstract Check 4: Simulating an LLM checking for contradictory claims.
    # Placeholder Logic: Checks for a direct contradiction
    # between the reported trend and the raw trend.
    if ("sales rose" in draft_report.lower() and "sales dropped" in ground_truth_data.lower()): # NOQA
        critiques.append("Logic Error: Contradictory information (report claims 'rose', data claims 'dropped').") # NOQA


def _check_formatting_completeness(draft_report: str, critiques: List[str]):
    """
    Simulates checking structural requirements, like Markdown
    validity and placeholder inclusion.
    """
    # Abstract Check 5: Ensures required structural tags are present.
    if "[" not in draft_report or "]" not in draft_report:
        critiques.append("Formatting: Missing required structural "
                         "tags (e.g., chart placeholder tags "
                         "like [CHART_1: ...]).")


def validate_report_draft(original_query: str, ground_truth_data: str, draft_report: str) -> Dict[str, str]: # NOQA
    """
    TOOL: Executes the Quality Assurance audit for a generated BI report by
    delegating checks to abstract, specialized functions.

    :param original_query: The user's initial business question.
    :param ground_truth_data: The facts and
    metrics provided by the Analyser Agent.
    :param draft_report: The narrative report generated by
    the Report Writer Agent.
    :return: A dictionary matching the required STATUS/CRITIQUE format.
    """
    critiques = []

    # 1. Hallucination Detection (The Truth Check)
    _check_hallucination_of_metric(draft_report, ground_truth_data, critiques)

    # 2. Responsiveness Check
    _check_temporal_scope_mismatch(original_query, draft_report, critiques)
    _check_core_query_addressal(original_query, draft_report, critiques)

    # 3. Formatting & Logic Check
    _check_formatting_completeness(draft_report, critiques)
    _check_logical_contradiction(draft_report, ground_truth_data, critiques)

    # --- Final Verdict ---
    if critiques:
        # Action: Return the FAIL status with detailed critique
        return {
            "STATUS": "FAIL",
            "CRITIQUE": "\n- " + "\n- ".join(critiques)
        }
    else:
        # Action: Return the PASS status
        return {
            "STATUS": "PASS",
            "CRITIQUE": "None"
        }
